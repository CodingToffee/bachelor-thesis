\chapter{\textbf{Requirements Analysis}}\label{grundlagen}
In order to select the most suitable technologies and design the system, it is first necessary to establish clear requirements. In this chapter, the aforementioned requirements will be enumerated and elucidated.
In order to maintain consistency regarding the compliance level, the terms "must," "should," and "will" were employed.
The following words shall be explained in brief. The term "must" is employed to signify an unconditional obligation, implying that the fulfillment of this requirement is not subject to discussion or negotiation. The term "should" conveys a degree of desirability, indicating that fulfillment of the requirement would be advantageous. The term "will" signifies that this particular requirement is currently under consideration for inclusion in the subsequent release. However, it is imperative to maintain awareness of this requirement so that the system can be designed in a manner that facilitates its seamless integration in the future.
\subsection{Functional System Requirements} % (from your requirements table)
\begin{tabularx}{\textwidth}{|X|X|}
	\hline
\textbf{Requirement}	& \textbf{Explanation} \\
	\hline
The system must show KPIs that are relevant for the sewing process	&  In the workshops there must be some KPIs that fit into the story of a textile production with a sewing process\\
	\hline
The system should show aditional KPIs that are relevant for the manufacturing industry in general	&  Workshop participants are from all sorts of companies within the manufacturing industry\\
	\hline
 The system must present these KPIs in a visual manner that provides information about the classification of the current value e.g. with colors and thresholds	& So that the management can act quickly upon the KPIs and does not need to lookup thresholds \\
	\hline
The system must provide the user with the ability to change the timeframe on which the KPIs are calculated	&  Especially when looking at historic data it is usefull to be able to set the timeframe\\
	\hline
The system should show graphs with historical data & Enables management to see trends and patterns\\
	\hline
\end{tabularx}

\subsection{Non-Functional Requirements} %(scalability, security, real-time processing)
\begin{tabularx}{\textwidth}{|X|X|}
	\hline
\textbf{Requirement}	&  \textbf{Explanation}\\
	\hline
The system must make use of open source software where possible	&  To be replecable by small and medium companies\\
	\hline
The system must be capable to generate all of the KPIs from the machine-data without installing any additional sensors	&  \\
	\hline
The system must be designed in a way that makes it easily scalable	&  Usually more than just one machine need to be considered for monitoring\\
	\hline
The system must be deployable with minimal effort	&  To be able to deploy elsewhere with not much effort \\
	\hline
The system must be capable to retrieve raw data via opc-ua	&  The PLC to which the sewing machine is connected publishes the data over opc-ua\\
	\hline
The system should make use of existing patterns, frameworks and solutions were possible	&  The system shall serve as a reference for other systems that are more readily implementable\\
	\hline
The system should update the KPIs in real-time (<10s)	&  To support timely interventions\\
	\hline
 The system must be able to run on a local machine and therefore independent of any cloud service	&  \\
	\hline
The system must provide the user with the ability to access the dashboard from within the shopfloor network	&  \\
	\hline
\end{tabularx}

\subsection{IoT Platform Selection} 
The raw data from the PLC had to undergo processing, storage, and visualization. The utility of IoT platforms stems from their ability to execute these functions and frequently extend beyond them.  These systems meet the criteria for scalability and leverage existing solutions. To ensure that the selected platform satisfies other requirements and does not conflict with any necessary ones, a decision support framework was developed. The present framework draws inspiration from the one proposed by Gustin et al. (cit. Gustin et al., 2022). The researchers identified a set of criteria and classified them into categories. The categories encompassed "Knock-Out," "Device Management," "Hosting," "General," and "Effort." Each category was assigned a weight, with the exception of the "Knock-Out" category. The "Knock-Out" category indicates that a criterion tagged with it must be met; otherwise, the platform will not be considered further. The weights are expressed as percentages, and when added together, they equal 100\%. In addition, each criterion is assigned a distinct weight, thereby enabling the allocation of greater significance to specific criteria. The evaluation of each platform is subsequently determined by the following formula:
\[ s_i = f_i \cdot 100P \cdot \mathit{weight}_{category} \cdot \mathit{weight}_{criterion} \]
In this context, $f_i$ denotes the fulfillment factor.
The newly developed framework is distinguished by the following characteristics: The criteria are flexible and should be altered according to the requirements. Gustin et al. concentrate on device management; however, this is not a salient issue in the context of the proposed system. The categories were modified to "Knock-Out," "High Importance," "Mid Importance," and "Low Importance." In this manner, the criteria are not constrained to a particular subject matter; rather, they can be assigned an extent of importance at will. The numerical values assigned to the categories are as follows: 1 for low importance, 2 for medium importance, and 3 for high importance. The new formula for calculating the platforms' score is more straightforward as well:
\[ s_i = f_i \cdot \mathit{weight}_{category} \]
The fulfillment factor is typically binary in nature. The value of the variable can be either one or zero; however, in some cases, it can also be fractional. For instance, it would be advantageous for the platforms to support additional communication protocols beyond OPC UA. Specifically, the focus is on HTTP, MQTT, CoAP, and AMQP. In the event that a given platform offers support for only one of these, it is awarded a quarter point. In the event that this is the case, it will be elucidated in the subsequent explanation. The fulfillment of the criteria was determined in the same manner as that employed by the researchers. An investigation was conducted into the documentation, website, and GitHub repository of the platform. In the event that information regarding the availability of the criterion was ascertained, the point was granted. In the absence of pertinent information, the concept in question was deemed to be nonexistent.
The subsequent paragraphs will provide detailed explanations for each of the aforementioned criteria. A selection of the materials was obtained from the publication by Gustin et al. if their utility was deemed to be beneficial. The remaining ones were developed in response to specific requirements.

\subsubsection{Knock-Out Criteria}
\textbf{Availability of Documentation}\\
The implementation, deployment, and utilization of the solution are contingent upon the availability of English-language documentation, which is imperative for effective operation. This criterion originates from the seminal contributions of Gustin et al.\\
\textbf{Cloud independence}\\
In order to guarantee that the platform can be hosted on a local server that is accessible via the shopfloor network and that no additional cloud services are required, this criterion was established. This criterion is derived directly from the stipulated requirements.\\
\textbf{Ability to process raw data and derive KPI's from it}\\
In order to visualize the KPIs, the data must first undergo processing, after which the KPIs are to be calculated based on the processed data. This criterion pertains to the requirement of calculating KPIs. \\
\textbf{OPC-UA capability}\\
The PLC that controls the sewing machine transmits the data via the OPC UA protocol. Therefore, it is imperative that the platform demonstrate its capacity to effectively manage this particular protocol. This criterion is predicated on the requirements.

\subsubsection{High Importance Criteria}
\textbf{Dashboarding Capabilities}\\
In order to facilitate the visualization of KPIs, the platform must possess the capacity to construct dashboards. This criterion pertains to the necessity of possessing the capacity for visualizing KPIs.\\
\textbf{Actively Maintained}\\
This criterion is instrumental in ensuring the platform's security and compatibility with evolving technologies and standards.The necessity for this criterion arises from the imperative for open-source software.\\
\textbf{Completion of Server SW}\\
This criterion offers insight into the ease with which the software can be installed. A score of one is assigned if a Docker image is provided, and a score of zero is assigned if only source code is available. This criterion is derived from the work of Gustin et al.\\
\textbf{Development of the server-side application}\\
This criterion delineates the ease with which rules can be created and data processed within the application. In the event that a rule engine (low code) is provided, a point will be awarded. In the event that an SDK is provided, a total of 0.5 points will be allotted. This criterion originates from the work of Gustin et al.\\
\textbf{Examples for Server-side implementation}\\
These examples methodically illustrate the server-side implementation process and the anticipated outcomes.This approach has been shown to expedite the implementation process.
This criterion originates from the work of Gustin et al.

\subsubsection{Medium Importance Criteria}
\textbf{Supports MQTT, HTTP, CoAP, AMQP}\\
The implementation of these protocols would significantly augment the system's scalability, as it would facilitate the connection of a greater number of machines, gateways, and microcontrollers. This criterion pertains to the necessity of having a scalable system with minimal effort.\\
\textbf{Availability of Tutorials}\\
Tutorials are instrumental in facilitating user comprehension of the platform and its applications, thereby accelerating the development process. This criterion originates from the work of Gustin et al.

\subsubsection{Low Importance Criteria}
\textbf{Fault Detection}\\
This feature facilitates the collection of data pertaining to anomalous behavior or fault conditions of the machine. Therefore, it facilitates the identification and resolution of potential issues. While it would certainly be a beneficial addition, this feature does not directly align with the primary objectives of the system.
This criterion is derived from the work of Gustin et al.\\
\textbf{Heartbeat Monitor}\\
This feature periodically ascertains the online status of the connected machine. Consequently, this would facilitate the identification of device connectivity issues and ensure system reliability.
This feature is commendable, yet it does not directly align with the primary function of the system.
This criterion is derived from the work of Gustin et al.\\\\


The  platforms to be evaluated were derived from two papers that themselves evaluated IoT platforms. Initially, the open-source platforms cited by Gustin et al. were selected. These include openBalen, Thingsboard, Kapua, OpenRemote, Ubuntu Core, FIWARE, OpenMTC, Mainflux, and DeviceHive. In a separate study, Turki's 2024 investigation focused exclusively on the evaluation of open-source Internet of Things (IoT) platforms, utilizing data derived from GitHub statistics. The following factors were taken into consideration: the stars that were given by users, health, contributors, open issues, closed issues, and releases. Due to the more objective nature of this evaluation, only the top five IoT platforms were selected. The restriction to a specific number was necessitated by the impracticality of evaluating an indefinite number of platforms, as this would have entailed an inordinate amount of time. The top five platforms identified in this study are Thingsboard, Digiot, Mainflux, OpenRemote, and IotSharp.  However, it should be noted that only two of these findings were in disjunction with those selected from Gustin et al.'s work. In the course of the research, the Node-RED platform emerged on a regular basis; however, it was not referenced in the evaluated documents. The platform was also mentioned by a colleague, and it was therefore given due consideration. Additionally, UMH was selected for evaluation because it builds upon robust open-source tools, such as Grafana and Apache Kafka, and supports a wide array of protocols.\\
The ensuing table 4.1 presents the results of the aforementioned calculations. It is imperative to note that only the platforms that met all of the Knock-Out criteria are displayed therein.\\

\begin{table}[H]
	%\toprule
	\caption{IoT Platform Evaluation}
	\label{tab:platform-evaluation}
	\centering
	\begin{tabu}{l @{\hspace{2cm}} r}
		\textbf{IoT Platform} & \textbf{Score} \\
		\midrule
		Thingsboard  & 19.5 \\
		Node-Red     & 21.5 \\
		FIWARE       & 19.0 \\
		OpenRemote   & 12.0 \\
		UMH          & 20.5 \\
		\bottomrule
	\end{tabu}
\end{table}





\subsection{KPI Selection and Justification}
 Of which the following were able to be calculated with the given metrics.
\\